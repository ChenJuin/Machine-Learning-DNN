{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ab1f93-843a-45d2-987b-f5462d836e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0351f8-1d7e-4c15-93f2-86ec9223193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从CSV文件加载数据\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # 跳过文件头部\n",
    "        for line in reader:\n",
    "            sentence, label = line\n",
    "            # 将标签转为整型，这里我们把'positive'转为1，把'negative'转为0\n",
    "            label = 1 if label == 'positive' else 0\n",
    "            data.append((sentence, label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e976e5-d372-4a6c-b87a-89a450cba15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集类\n",
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence, label = self.data[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return input_ids, attention_mask, torch.tensor(label)  # 标签转为Tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4da5ef-c686-4858-9b89-896ab892dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自定义模型\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.neck = nn.Linear(hidden_dim, 256)\n",
    "        self.tail = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        _, (h_n, _) = self.lstm(embedded)\n",
    "        features = self.neck(h_n[-1])\n",
    "        features = self.dropout(features)\n",
    "        logits = self.tail(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68808aa-d162-4a11-8249-2b32258e767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义阈值清洗方法\n",
    "def threshold_cleaning(predictions, labels, threshold):\n",
    "    clean_indices = []\n",
    "    for i in range(len(predictions)):\n",
    "        if abs(predictions[i] - labels[i]) <= threshold:\n",
    "            clean_indices.append(i)\n",
    "    return clean_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357e8363-afa4-44aa-b8fe-28ad3500a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d794e9e131348319c2523a8d36c2f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb2b6333651435b93cab1affc4ce9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c66c0aed23e45629cf2474183819246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载数据集并进行分割\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "data = load_data('IMDB-NY.csv')\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21dc55f-d7a3-4cbc-ab77-44e2c173daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取词汇表大小\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "# 创建训练集和验证集\n",
    "train_dataset = IMDbDataset(train_data, tokenizer)\n",
    "val_dataset = IMDbDataset(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f771d3ee-1a20-4265-bfcc-ffb215cd5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_epochs = 50\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85328c66-3301-4427-86b7-9feecfb5a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4993fc9-caf7-4654-b0af-7e1700721c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMClassifier(embedding_dim, hidden_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d470c148-93e2-4a8e-9a48-3dc5212baf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1757cc5-3312-4c84-b62f-fc830174c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.6932, Accuracy: 0.5074\n",
      "Val Loss: 0.6932, Val Accuracy: 0.5094\n",
      "Epoch 2/50, Loss: 0.6926, Accuracy: 0.5153\n",
      "Val Loss: 0.6929, Val Accuracy: 0.5162\n",
      "Epoch 3/50, Loss: 0.6921, Accuracy: 0.5187\n",
      "Val Loss: 0.6925, Val Accuracy: 0.5233\n",
      "Epoch 4/50, Loss: 0.6912, Accuracy: 0.5288\n",
      "Val Loss: 0.6928, Val Accuracy: 0.5172\n",
      "Epoch 5/50, Loss: 0.6900, Accuracy: 0.5352\n",
      "Val Loss: 0.6921, Val Accuracy: 0.5263\n",
      "Epoch 6/50, Loss: 0.6883, Accuracy: 0.5422\n",
      "Val Loss: 0.6926, Val Accuracy: 0.5283\n",
      "Epoch 7/50, Loss: 0.6858, Accuracy: 0.5498\n",
      "Val Loss: 0.6906, Val Accuracy: 0.5344\n",
      "Epoch 8/50, Loss: 0.6816, Accuracy: 0.5613\n",
      "Val Loss: 0.6855, Val Accuracy: 0.5589\n",
      "Epoch 9/50, Loss: 0.6688, Accuracy: 0.5869\n",
      "Val Loss: 0.6714, Val Accuracy: 0.5839\n",
      "Epoch 10/50, Loss: 0.6580, Accuracy: 0.6087\n",
      "Val Loss: 0.6651, Val Accuracy: 0.5972\n",
      "Epoch 11/50, Loss: 0.6451, Accuracy: 0.6325\n",
      "Val Loss: 0.6561, Val Accuracy: 0.6173\n",
      "Epoch 12/50, Loss: 0.6354, Accuracy: 0.6456\n",
      "Val Loss: 0.6561, Val Accuracy: 0.6222\n",
      "Epoch 13/50, Loss: 0.6291, Accuracy: 0.6551\n",
      "Val Loss: 0.6534, Val Accuracy: 0.6276\n",
      "Epoch 14/50, Loss: 0.6237, Accuracy: 0.6607\n",
      "Val Loss: 0.6558, Val Accuracy: 0.6204\n",
      "Epoch 15/50, Loss: 0.6182, Accuracy: 0.6643\n",
      "Val Loss: 0.6546, Val Accuracy: 0.6278\n",
      "Epoch 16/50, Loss: 0.6092, Accuracy: 0.6783\n",
      "Val Loss: 0.6561, Val Accuracy: 0.6425\n",
      "Epoch 17/50, Loss: 0.6046, Accuracy: 0.6820\n",
      "Val Loss: 0.6682, Val Accuracy: 0.6243\n",
      "Epoch 18/50, Loss: 0.6062, Accuracy: 0.6765\n",
      "Val Loss: 0.6518, Val Accuracy: 0.6365\n",
      "Epoch 19/50, Loss: 0.6045, Accuracy: 0.6702\n",
      "Val Loss: 0.6539, Val Accuracy: 0.6254\n",
      "Epoch 20/50, Loss: 0.5971, Accuracy: 0.6788\n",
      "Val Loss: 0.6521, Val Accuracy: 0.6330\n",
      "Epoch 21/50, Loss: 0.5907, Accuracy: 0.6886\n",
      "Val Loss: 0.6520, Val Accuracy: 0.6405\n",
      "Epoch 22/50, Loss: 0.6139, Accuracy: 0.6648\n",
      "Val Loss: 0.6559, Val Accuracy: 0.6293\n",
      "Epoch 23/50, Loss: 0.5851, Accuracy: 0.6906\n",
      "Val Loss: 0.6555, Val Accuracy: 0.6436\n",
      "Epoch 24/50, Loss: 0.5880, Accuracy: 0.6884\n",
      "Val Loss: 0.6574, Val Accuracy: 0.6293\n",
      "Epoch 25/50, Loss: 0.5765, Accuracy: 0.6990\n",
      "Val Loss: 0.6573, Val Accuracy: 0.6365\n",
      "Epoch 26/50, Loss: 0.5799, Accuracy: 0.7007\n",
      "Val Loss: 0.6527, Val Accuracy: 0.6485\n",
      "Epoch 27/50, Loss: 0.5677, Accuracy: 0.7174\n",
      "Val Loss: 0.6491, Val Accuracy: 0.6501\n",
      "Epoch 28/50, Loss: 0.5798, Accuracy: 0.7056\n",
      "Val Loss: 0.6546, Val Accuracy: 0.6551\n",
      "Epoch 29/50, Loss: 0.5579, Accuracy: 0.7256\n",
      "Val Loss: 0.6998, Val Accuracy: 0.6249\n",
      "Epoch 30/50, Loss: 0.5550, Accuracy: 0.7296\n",
      "Val Loss: 0.6546, Val Accuracy: 0.6511\n",
      "Epoch 31/50, Loss: 0.5503, Accuracy: 0.7322\n",
      "Val Loss: 0.6493, Val Accuracy: 0.6550\n",
      "Epoch 32/50, Loss: 0.5521, Accuracy: 0.7301\n",
      "Val Loss: 0.6717, Val Accuracy: 0.6515\n",
      "Epoch 33/50, Loss: 0.5415, Accuracy: 0.7408\n",
      "Val Loss: 0.6603, Val Accuracy: 0.6527\n",
      "Epoch 34/50, Loss: 0.5662, Accuracy: 0.7164\n",
      "Val Loss: 0.6641, Val Accuracy: 0.6467\n",
      "Epoch 35/50, Loss: 0.5323, Accuracy: 0.7479\n",
      "Val Loss: 0.6619, Val Accuracy: 0.6582\n",
      "Epoch 36/50, Loss: 0.5249, Accuracy: 0.7527\n",
      "Val Loss: 0.6666, Val Accuracy: 0.6529\n",
      "Epoch 37/50, Loss: 0.5332, Accuracy: 0.7445\n",
      "Val Loss: 0.6753, Val Accuracy: 0.6535\n",
      "Epoch 38/50, Loss: 0.5198, Accuracy: 0.7551\n",
      "Val Loss: 0.6607, Val Accuracy: 0.6559\n",
      "Epoch 39/50, Loss: 0.5129, Accuracy: 0.7610\n",
      "Val Loss: 0.6799, Val Accuracy: 0.6562\n",
      "Epoch 40/50, Loss: 0.5238, Accuracy: 0.7463\n",
      "Val Loss: 0.6855, Val Accuracy: 0.6305\n",
      "Epoch 41/50, Loss: 0.5659, Accuracy: 0.7136\n",
      "Val Loss: 0.6852, Val Accuracy: 0.6157\n",
      "Epoch 42/50, Loss: 0.5361, Accuracy: 0.7259\n",
      "Val Loss: 0.6877, Val Accuracy: 0.6452\n",
      "Epoch 43/50, Loss: 0.5058, Accuracy: 0.7611\n",
      "Val Loss: 0.6951, Val Accuracy: 0.6511\n",
      "Epoch 44/50, Loss: 0.5053, Accuracy: 0.7574\n",
      "Val Loss: 0.6890, Val Accuracy: 0.6339\n",
      "Epoch 45/50, Loss: 0.5026, Accuracy: 0.7540\n",
      "Val Loss: 0.7026, Val Accuracy: 0.6320\n",
      "Epoch 46/50, Loss: 0.4937, Accuracy: 0.7597\n",
      "Val Loss: 0.6999, Val Accuracy: 0.6387\n",
      "Epoch 47/50, Loss: 0.4862, Accuracy: 0.7721\n",
      "Val Loss: 0.6943, Val Accuracy: 0.6446\n",
      "Epoch 48/50, Loss: 0.4784, Accuracy: 0.7832\n",
      "Val Loss: 0.7244, Val Accuracy: 0.6503\n",
      "Epoch 49/50, Loss: 0.4730, Accuracy: 0.7852\n",
      "Val Loss: 0.7219, Val Accuracy: 0.6497\n",
      "Epoch 50/50, Loss: 0.4637, Accuracy: 0.7920\n",
      "Val Loss: 0.7172, Val Accuracy: 0.6462\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "best_val_loss = float('inf')\n",
    "no_improve_epoch = 0\n",
    "max_no_improve_epoch = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 计算准确度\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        total_correct += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # 验证步骤\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_correct = 0\n",
    "    total_val_samples = 0\n",
    "    all_val_labels = []\n",
    "    all_val_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_dataloader:\n",
    "            val_input_ids, val_attention_mask, val_labels = val_batch\n",
    "            val_input_ids = val_input_ids.to(device)\n",
    "            val_attention_mask = val_attention_mask.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            val_logits = model(val_input_ids, val_attention_mask)\n",
    "            val_loss = criterion(val_logits, val_labels)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            # 计算验证集的准确度\n",
    "            val_predictions = torch.argmax(val_logits, dim=1)\n",
    "            total_val_correct += (val_predictions == val_labels).sum().item()\n",
    "            total_val_samples += val_labels.size(0)\n",
    "            all_val_predictions.extend(val_predictions.cpu().numpy())\n",
    "            all_val_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "    average_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = total_val_correct / total_val_samples\n",
    "    print(f'Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 使用阈值清洗方法检测噪声\n",
    "    clean_indices = threshold_cleaning(all_val_predictions, all_val_labels, threshold)\n",
    "    clean_val_labels = np.array(all_val_labels)[clean_indices]\n",
    "    clean_val_predictions = np.array(all_val_predictions)[clean_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
